{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 01\n",
    "En este ejemplo vamos a crear una neurona artificial y vamos a entrenarla para hacer que tenga el comportamiento de una compuerta OR. A diferencia de la sesión pasada, vamos a entrenar desde cero nuestra neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de la sesión pasada. Nota que en inicializar capa invertí la forma de W para que no tengamos que hacer la transposición de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializarCapa(numCaracteristicas, numNeuronas):\n",
    "    w = np.random.rand(numNeuronas,numCaracteristicas)\n",
    "    b = np.random.rand(numNeuronas,1)\n",
    "    return w,b\n",
    "\n",
    "def calcularZ(w,x,b):\n",
    "    z = np.dot(w,x) + b     \n",
    "    return z\n",
    "\n",
    "def activacion(z):\n",
    "    y = 1 / (1 + np.exp(-z))\n",
    "    return y\n",
    "\n",
    "def capaNeuronal(w,x,b):\n",
    "    z = calcularZ(w,x,b)\n",
    "    y_pred = activacion(z)\n",
    "    return z, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a calcular el error logístico, el cual es muy útil para saber que tal va nuestro algoritmo. \n",
    "El error logístico se calcula con la ecuación:\n",
    "\n",
    "$E = \\frac{1}{m} (-Y log(y_{pred}) + (1 - Y) log(1 - y_{pred}))$\n",
    "\n",
    "La ecuación funciona así: \n",
    "- Si $Y$ y $Y_{pred}$ son 0, el error es $E=0$\n",
    "- Si $Y$ y $Y_{pred}$ son 1, el error es $E=0$\n",
    "- $Log(0) = 1$ y $Log(1) = 0$ Por ende, la ecuación solamente tiene errores cuando $Y$ y $Y_{pred}$ son diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularError(y_esperado, y_obtenido):\n",
    "    numMuestras = y_esperado.shape[0]\n",
    "    error = - (y_esperado *np.log(y_obtenido) + (1 - y_esperado)*np.log(1 - y_obtenido))\n",
    "    error = np.sum(error) / numMuestras\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las derivada cuando solo hay una capa neuronal es tan simple como $Y_{pred} - Y$, con ello, podemos calcular las derivadas de los pesos como:\n",
    "\n",
    "$\\frac{dE}{dz} = Y_{pred} - Y$\n",
    "\n",
    "$\\frac{dE}{dw} = \\frac{dE}{dz} \\cdot X^{T} $\n",
    "\n",
    "$\\frac{dE}{db} = \\frac{dE}{dz}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_derivadas(y_esperado, y_obtenido, entradas):\n",
    "    dz = y_obtenido - y_esperado    \n",
    "    dw = np.dot(dz,entradas.T)\n",
    "    db = np.sum(dz, axis=1, keepdims=True)\n",
    "    return dz, dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "Ahora, vamos a entrenar nuestra red neuronal. Cada uno de los pasos del algoritmo nos acercará a un error cada vez menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los tamaños de X deben ser:(NumCaracteristicas, NumMuestras)\n",
      "(2, 4)\n",
      "Los tamaños de Y deben ser:(NumSalidas, NumMuestras)\n",
      "(1, 4)\n",
      "Epoch:0\n",
      "Error: 2.212492339292866\n",
      "Epoch:100\n",
      "Error: 1.6297121933499774\n",
      "Epoch:200\n",
      "Error: 1.42173519146556\n",
      "Epoch:300\n",
      "Error: 1.2735320525886482\n",
      "Epoch:400\n",
      "Error: 1.1530337250013558\n",
      "Epoch:500\n",
      "Error: 1.051957151879547\n",
      "Epoch:600\n",
      "Error: 0.9659836682272147\n",
      "Epoch:700\n",
      "Error: 0.8920900524677952\n",
      "Epoch:800\n",
      "Error: 0.8279903212233977\n",
      "Epoch:900\n",
      "Error: 0.7719193363900616\n",
      "Epoch:1000\n",
      "Error: 0.722499133967463\n",
      "Epoch:1100\n",
      "Error: 0.6786429961073558\n",
      "Epoch:1200\n",
      "Error: 0.6394848407380205\n",
      "Epoch:1300\n",
      "Error: 0.6043271316600314\n",
      "Epoch:1400\n",
      "Error: 0.572602350671644\n",
      "Epoch:1500\n",
      "Error: 0.5438443288734506\n",
      "Epoch:1600\n",
      "Error: 0.517666731639499\n",
      "Epoch:1700\n",
      "Error: 0.4937467522214743\n",
      "Epoch:1800\n",
      "Error: 0.4718126244193126\n",
      "Epoch:1900\n",
      "Error: 0.4516339606821467\n",
      "Epoch:2000\n",
      "Error: 0.43301420130702684\n",
      "Epoch:2100\n",
      "Error: 0.4157846571265167\n",
      "Epoch:2200\n",
      "Error: 0.3997997671491164\n",
      "Epoch:2300\n",
      "Error: 0.38493329159835804\n",
      "Epoch:2400\n",
      "Error: 0.3710752318402983\n",
      "Epoch:2500\n",
      "Error: 0.35812932015540094\n",
      "Epoch:2600\n",
      "Error: 0.34601095995364606\n",
      "Epoch:2700\n",
      "Error: 0.334645524829432\n",
      "Epoch:2800\n",
      "Error: 0.323966945574175\n",
      "Epoch:2900\n",
      "Error: 0.3139165298519774\n",
      "Epoch:3000\n",
      "Error: 0.30444197107193494\n",
      "Epoch:3100\n",
      "Error: 0.2954965120411795\n",
      "Epoch:3200\n",
      "Error: 0.28703823596281375\n",
      "Epoch:3300\n",
      "Error: 0.2790294627666419\n",
      "Epoch:3400\n",
      "Error: 0.2714362330050064\n",
      "Epoch:3500\n",
      "Error: 0.2642278648899676\n",
      "Epoch:3600\n",
      "Error: 0.2573765726992946\n",
      "Epoch:3700\n",
      "Error: 0.25085713689349226\n",
      "Epoch:3800\n",
      "Error: 0.24464661798255338\n",
      "Epoch:3900\n",
      "Error: 0.23872410754939394\n",
      "Epoch:4000\n",
      "Error: 0.2330705109462187\n",
      "Epoch:4100\n",
      "Error: 0.22766835708372485\n",
      "Epoch:4200\n",
      "Error: 0.2225016314726928\n",
      "Epoch:4300\n",
      "Error: 0.21755562928551414\n",
      "Epoch:4400\n",
      "Error: 0.21281682570717417\n",
      "Epoch:4500\n",
      "Error: 0.20827276126124886\n",
      "Epoch:4600\n",
      "Error: 0.20391194014266587\n",
      "Epoch:4700\n",
      "Error: 0.19972373987807848\n",
      "Epoch:4800\n",
      "Error: 0.1956983308770018\n",
      "Epoch:4900\n",
      "Error: 0.19182660464060122\n",
      "Epoch:5000\n",
      "Error: 0.18810010956692907\n",
      "Epoch:5100\n",
      "Error: 0.18451099343684702\n",
      "Epoch:5200\n",
      "Error: 0.18105195178837102\n",
      "Epoch:5300\n",
      "Error: 0.17771618149227647\n",
      "Epoch:5400\n",
      "Error: 0.17449733893151523\n",
      "Epoch:5500\n",
      "Error: 0.17138950226381966\n",
      "Epoch:5600\n",
      "Error: 0.16838713731275068\n",
      "Epoch:5700\n",
      "Error: 0.16548506668915164\n",
      "Epoch:5800\n",
      "Error: 0.16267844179387092\n",
      "Epoch:5900\n",
      "Error: 0.15996271739486717\n",
      "Epoch:6000\n",
      "Error: 0.15733362850842794\n",
      "Epoch:6100\n",
      "Error: 0.15478716934603493\n",
      "Epoch:6200\n",
      "Error: 0.1523195741160451\n",
      "Epoch:6300\n",
      "Error: 0.14992729949349493\n",
      "Epoch:6400\n",
      "Error: 0.14760700859238973\n",
      "Epoch:6500\n",
      "Error: 0.14535555629328656\n",
      "Epoch:6600\n",
      "Error: 0.14316997579514462\n",
      "Epoch:6700\n",
      "Error: 0.1410474662746372\n",
      "Epoch:6800\n",
      "Error: 0.13898538154859943\n",
      "Epoch:6900\n",
      "Error: 0.13698121964634918\n",
      "Epoch:7000\n",
      "Error: 0.13503261320830295\n",
      "Epoch:7100\n",
      "Error: 0.13313732063597672\n",
      "Epoch:7200\n",
      "Error: 0.13129321792603738\n",
      "Epoch:7300\n",
      "Error: 0.12949829112788966\n",
      "Epoch:7400\n",
      "Error: 0.12775062937026044\n",
      "Epoch:7500\n",
      "Error: 0.12604841840762077\n",
      "Epoch:7600\n",
      "Error: 0.1243899346420574\n",
      "Epoch:7700\n",
      "Error: 0.12277353958044704\n",
      "Epoch:7800\n",
      "Error: 0.12119767469062029\n",
      "Epoch:7900\n",
      "Error: 0.11966085662358873\n",
      "Epoch:8000\n",
      "Error: 0.11816167277197097\n",
      "Epoch:8100\n",
      "Error: 0.11669877713749113\n",
      "Epoch:8200\n",
      "Error: 0.11527088648288711\n",
      "Epoch:8300\n",
      "Error: 0.1138767767457744\n",
      "Epoch:8400\n",
      "Error: 0.11251527969400948\n",
      "Epoch:8500\n",
      "Error: 0.11118527980389326\n",
      "Epoch:8600\n",
      "Error: 0.1098857113441742\n",
      "Epoch:8700\n",
      "Error: 0.10861555565028165\n",
      "Epoch:8800\n",
      "Error: 0.10737383857454395\n",
      "Epoch:8900\n",
      "Error: 0.10615962809934344\n",
      "Epoch:9000\n",
      "Error: 0.10497203210125448\n",
      "Epoch:9100\n",
      "Error: 0.10381019625519686\n",
      "Epoch:9200\n",
      "Error: 0.10267330206853185\n",
      "Epoch:9300\n",
      "Error: 0.10156056503584572\n",
      "Epoch:9400\n",
      "Error: 0.10047123290590647\n",
      "Epoch:9500\n",
      "Error: 0.09940458405296647\n",
      "Epoch:9600\n",
      "Error: 0.09835992594517523\n",
      "Epoch:9700\n",
      "Error: 0.09733659370346438\n",
      "Epoch:9800\n",
      "Error: 0.09633394874474664\n",
      "Epoch:9900\n",
      "Error: 0.09535137750376615\n",
      "Epoch:10000\n",
      "Error: 0.09438829022835454\n",
      "Epoch:10100\n",
      "Error: 0.09344411984324599\n",
      "Epoch:10200\n",
      "Error: 0.09251832087796123\n",
      "Epoch:10300\n",
      "Error: 0.09161036845460617\n",
      "Epoch:10400\n",
      "Error: 0.09071975733173568\n",
      "Epoch:10500\n",
      "Error: 0.08984600100070654\n",
      "Epoch:10600\n",
      "Error: 0.08898863083120052\n",
      "Epoch:10700\n",
      "Error: 0.08814719526285068\n",
      "Epoch:10800\n",
      "Error: 0.0873212590400898\n",
      "Epoch:10900\n",
      "Error: 0.08651040248758032\n",
      "Epoch:11000\n",
      "Error: 0.08571422082373101\n",
      "Epoch:11100\n",
      "Error: 0.08493232351000662\n",
      "Epoch:11200\n",
      "Error: 0.08416433363387658\n",
      "Epoch:11300\n",
      "Error: 0.08340988732340181\n",
      "Epoch:11400\n",
      "Error: 0.08266863319158849\n",
      "Epoch:11500\n",
      "Error: 0.08194023180877327\n",
      "Epoch:11600\n",
      "Error: 0.08122435520139815\n",
      "Epoch:11700\n",
      "Error: 0.08052068637566616\n",
      "Epoch:11800\n",
      "Error: 0.07982891886465028\n",
      "Epoch:11900\n",
      "Error: 0.07914875629752309\n",
      "Epoch:12000\n",
      "Error: 0.07847991198966406\n",
      "Epoch:12100\n",
      "Error: 0.07782210855248262\n",
      "Epoch:12200\n",
      "Error: 0.07717507752185142\n",
      "Epoch:12300\n",
      "Error: 0.07653855900414289\n",
      "Epoch:12400\n",
      "Error: 0.0759123013388957\n",
      "Epoch:12500\n",
      "Error: 0.07529606077721387\n",
      "Epoch:12600\n",
      "Error: 0.07468960117505455\n",
      "Epoch:12700\n",
      "Error: 0.07409269370060777\n",
      "Epoch:12800\n",
      "Error: 0.07350511655502\n",
      "Epoch:12900\n",
      "Error: 0.07292665470576408\n",
      "Epoch:13000\n",
      "Error: 0.07235709963199195\n",
      "Epoch:13100\n",
      "Error: 0.07179624908124581\n",
      "Epoch:13200\n",
      "Error: 0.07124390683695303\n",
      "Epoch:13300\n",
      "Error: 0.07069988249614313\n",
      "Epoch:13400\n",
      "Error: 0.07016399125687317\n",
      "Epoch:13500\n",
      "Error: 0.06963605371487241\n",
      "Epoch:13600\n",
      "Error: 0.06911589566894297\n",
      "Epoch:13700\n",
      "Error: 0.06860334793468527\n",
      "Epoch:13800\n",
      "Error: 0.06809824616612943\n",
      "Epoch:13900\n",
      "Error: 0.0676004306848951\n",
      "Epoch:14000\n",
      "Error: 0.06710974631650701\n",
      "Epoch:14100\n",
      "Error: 0.06662604223351894\n",
      "Epoch:14200\n",
      "Error: 0.06614917180512551\n",
      "Epoch:14300\n",
      "Error: 0.06567899245294553\n",
      "Epoch:14400\n",
      "Error: 0.06521536551268861\n",
      "Epoch:14500\n",
      "Error: 0.06475815610142477\n",
      "Epoch:14600\n",
      "Error: 0.06430723299019958\n",
      "Epoch:14700\n",
      "Error: 0.06386246848174015\n",
      "Epoch:14800\n",
      "Error: 0.0634237382930221\n",
      "Epoch:14900\n",
      "Error: 0.06299092144247345\n",
      "Epoch:15000\n",
      "Error: 0.06256390014159881\n",
      "Epoch:15100\n",
      "Error: 0.06214255969083211\n",
      "Epoch:15200\n",
      "Error: 0.061726788379421985\n",
      "Epoch:15300\n",
      "Error: 0.061316477389169385\n",
      "Epoch:15400\n",
      "Error: 0.06091152070184778\n",
      "Epoch:15500\n",
      "Error: 0.06051181501014307\n",
      "Epoch:15600\n",
      "Error: 0.060117259631957985\n",
      "Epoch:15700\n",
      "Error: 0.059727756427935284\n",
      "Epoch:15800\n",
      "Error: 0.05934320972205683\n",
      "Epoch:15900\n",
      "Error: 0.05896352622518959\n",
      "Epoch:16000\n",
      "Error: 0.058588614961452026\n",
      "Epoch:16100\n",
      "Error: 0.0582183871972766\n",
      "Epoch:16200\n",
      "Error: 0.057852756373059956\n",
      "Epoch:16300\n",
      "Error: 0.05749163803728627\n",
      "Epoch:16400\n",
      "Error: 0.05713494978302397\n",
      "Epoch:16500\n",
      "Error: 0.05678261118669691\n",
      "Epoch:16600\n",
      "Error: 0.056434543749032416\n",
      "Epoch:16700\n",
      "Error: 0.05609067083810055\n",
      "Epoch:16800\n",
      "Error: 0.055750917634359166\n",
      "Epoch:16900\n",
      "Error: 0.05541521107761572\n",
      "Epoch:17000\n",
      "Error: 0.05508347981584062\n",
      "Epoch:17100\n",
      "Error: 0.05475565415574801\n",
      "Epoch:17200\n",
      "Error: 0.05443166601507573\n",
      "Epoch:17300\n",
      "Error: 0.05411144887649829\n",
      "Epoch:17400\n",
      "Error: 0.053794937743108534\n",
      "Epoch:17500\n",
      "Error: 0.05348206909540346\n",
      "Epoch:17600\n",
      "Error: 0.053172780849717716\n",
      "Epoch:17700\n",
      "Error: 0.0528670123180477\n",
      "Epoch:17800\n",
      "Error: 0.052564704169213286\n",
      "Epoch:17900\n",
      "Error: 0.0522657983913034\n",
      "Epoch:18000\n",
      "Error: 0.05197023825535933\n",
      "Epoch:18100\n",
      "Error: 0.051677968280246865\n",
      "Epoch:18200\n",
      "Error: 0.051388934198670765\n",
      "Epoch:18300\n",
      "Error: 0.05110308292429384\n",
      "Epoch:18400\n",
      "Error: 0.0508203625199103\n",
      "Epoch:18500\n",
      "Error: 0.05054072216664562\n",
      "Epoch:18600\n",
      "Error: 0.050264112134134016\n"
     ]
    }
   ],
   "source": [
    "w,b = inicializarCapa(numCaracteristicas = 2,numNeuronas = 1)\n",
    "\n",
    "#Funcion OR:\n",
    "x = np.array([[0,0]\n",
    "             ,[0,1]\n",
    "             ,[1,0]\n",
    "             ,[1,1]]).T\n",
    "y_esperado = np.array([[0,1,1,1]])\n",
    "\n",
    "print(\"Los tamaños de X deben ser:(NumCaracteristicas, NumMuestras)\")\n",
    "print(x.shape)\n",
    "print(\"Los tamaños de Y deben ser:(NumSalidas, NumMuestras)\")\n",
    "print(y_esperado.shape)\n",
    "\n",
    "#Hiperparámetros:\n",
    "\n",
    "#Learning rate\n",
    "lr = 0.01\n",
    "#Error mínimo al que queremos llegar\n",
    "minError = 0.05\n",
    "#Cantidad de veces que se entrenará la red neuronal.\n",
    "maxEpochs = 100000\n",
    "\n",
    "for counter in range(0,maxEpochs):\n",
    "    #Hacemos la propagación hacia el frente.\n",
    "    z, y_obtenido = capaNeuronal(w,x,b)\n",
    "    \n",
    "    #Calculamos el error.\n",
    "    error = calcularError(y_esperado, y_obtenido)\n",
    "    \n",
    "    #Luego hacemos la retropropagación para obtener las derivadas.\n",
    "    dz, dw, db = calcular_derivadas(y_esperado, y_obtenido, x)\n",
    "    \n",
    "    #Con las derivadas, ajustamos los pesos de la siguiente manera:\n",
    "    w = w - lr * dw\n",
    "    b = b - lr * db\n",
    "    \n",
    "    #Si el error ha sobrepasado el mínimo, detenemos el algoritmo.\n",
    "    if(error < minError):\n",
    "        break;\n",
    "    \n",
    "    # Cada 100 Epocas vemos como va el error.\n",
    "    if counter % 100 == 0:\n",
    "        print(\"Epoch:\"+str(counter))\n",
    "        print(\"Error: \"+str(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos el código. Para obtener los resultados, corremos la red neuronal sobre una prueba (sin hacer la retropropagación, la matriz w y el vector b ya tienen contenidos los pesos sinápticos que generan el comportamiento, si haces retropropagación los desajustas!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entradas [[1]\n",
      " [0]]\n",
      "Genera salida [[0.98901595]]o bien (redondeado)...[[1.]]\n"
     ]
    }
   ],
   "source": [
    "#Probando:\n",
    "x_test = np.array([[1,0]]).T\n",
    "_, y_test = capaNeuronal(w,x_test,b)\n",
    "\n",
    "print(\"Entradas \"+str(x_test))\n",
    "print(\"Genera salida \"+str(y_test)+\"o bien (redondeado)...\"+str(np.round(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
